{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a4f44a2",
   "metadata": {},
   "source": [
    "# Week 3: Semantic Search and Retrieval\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand semantic search concepts and applications\n",
    "- Learn about vector databases and similarity search\n",
    "- Implement vector search for LLM applications\n",
    "- Explore different embedding models and techniques\n",
    "- Introduction to RAG-based architectures\n",
    "\n",
    "## Table of Contents\n",
    "1. [Introduction to Semantic Search](#introduction-to-semantic-search)\n",
    "2. [Vector Embeddings for Search](#vector-embeddings-for-search)\n",
    "3. [Similarity Metrics](#similarity-metrics)\n",
    "4. [Vector Databases](#vector-databases)\n",
    "5. [Implementing Vector Search](#implementing-vector-search)\n",
    "6. [RAG Architecture](#rag-architecture)\n",
    "7. [Advanced Retrieval Techniques](#advanced-retrieval-techniques)\n",
    "8. [Exercises](#exercises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24b804f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install sentence-transformers faiss-cpu chromadb pinecone-client\n",
    "!pip install transformers torch numpy pandas matplotlib seaborn\n",
    "!pip install sklearn datasets openai tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224336f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA\n",
    "import chromadb\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d31373",
   "metadata": {},
   "source": [
    "## Introduction to Semantic Search\n",
    "\n",
    "Semantic search goes beyond keyword matching to understand the meaning and context of queries and documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cd3261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison: Traditional vs Semantic Search\n",
    "def compare_search_approaches():\n",
    "    print(\"Traditional Keyword Search vs Semantic Search\\n\")\n",
    "    \n",
    "    comparison = {\n",
    "        \"Aspect\": [\"Matching\", \"Understanding\", \"Synonyms\", \"Context\", \"Ranking\"],\n",
    "        \"Traditional Search\": [\n",
    "            \"Exact keyword matching\",\n",
    "            \"No understanding of meaning\",\n",
    "            \"Poor synonym handling\",\n",
    "            \"No context awareness\",\n",
    "            \"Based on keyword frequency\"\n",
    "        ],\n",
    "        \"Semantic Search\": [\n",
    "            \"Meaning-based matching\",\n",
    "            \"Understands intent and context\",\n",
    "            \"Excellent synonym handling\",\n",
    "            \"Context-aware\",\n",
    "            \"Based on semantic similarity\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(comparison)\n",
    "    print(df.to_string(index=False))\n",
    "    \n",
    "    # Example queries\n",
    "    print(\"\\n\\nExample Scenarios:\")\n",
    "    examples = [\n",
    "        {\n",
    "            \"Query\": \"machine learning algorithms\",\n",
    "            \"Traditional\": \"Finds documents with exact words 'machine', 'learning', 'algorithms'\",\n",
    "            \"Semantic\": \"Also finds 'AI methods', 'neural networks', 'deep learning models'\"\n",
    "        },\n",
    "        {\n",
    "            \"Query\": \"How to cook pasta?\",\n",
    "            \"Traditional\": \"Looks for 'cook' and 'pasta' keywords\",\n",
    "            \"Semantic\": \"Understands cooking intent, finds recipes, preparation methods\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for i, example in enumerate(examples, 1):\n",
    "        print(f\"\\n{i}. Query: '{example['Query']}'\")\n",
    "        print(f\"   Traditional: {example['Traditional']}\")\n",
    "        print(f\"   Semantic: {example['Semantic']}\")\n",
    "\n",
    "compare_search_approaches()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abab5b9b",
   "metadata": {},
   "source": [
    "## Vector Embeddings for Search\n",
    "\n",
    "Vector embeddings convert text into dense numerical representations that capture semantic meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316cd817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sentence transformer model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Sample documents\n",
    "documents = [\n",
    "    \"Machine learning is a subset of artificial intelligence.\",\n",
    "    \"Deep learning uses neural networks with multiple layers.\",\n",
    "    \"Natural language processing helps computers understand human language.\",\n",
    "    \"Computer vision enables machines to interpret visual information.\",\n",
    "    \"Reinforcement learning involves training agents through rewards.\",\n",
    "    \"Data science combines statistics, programming, and domain expertise.\",\n",
    "    \"Python is a popular programming language for AI development.\",\n",
    "    \"Transformers revolutionized natural language understanding.\",\n",
    "    \"GPT models are large language models for text generation.\",\n",
    "    \"BERT is a bidirectional encoder for language understanding.\"\n",
    "]\n",
    "\n",
    "# Generate embeddings\n",
    "embeddings = model.encode(documents)\n",
    "\n",
    "print(f\"Number of documents: {len(documents)}\")\n",
    "print(f\"Embedding dimension: {embeddings.shape[1]}\")\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "\n",
    "# Show first document and its embedding\n",
    "print(f\"\\nFirst document: '{documents[0]}'\")\n",
    "print(f\"First 10 embedding values: {embeddings[0][:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5958c9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize embeddings using PCA\n",
    "def visualize_embeddings(embeddings, documents, title=\"Document Embeddings\"):\n",
    "    # Reduce dimensionality to 2D for visualization\n",
    "    pca = PCA(n_components=2)\n",
    "    embeddings_2d = pca.fit_transform(embeddings)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], alpha=0.7, s=100)\n",
    "    \n",
    "    # Add labels for each point\n",
    "    for i, doc in enumerate(documents):\n",
    "        # Truncate long documents for readability\n",
    "        label = doc[:30] + \"...\" if len(doc) > 30 else doc\n",
    "        plt.annotate(label, (embeddings_2d[i, 0], embeddings_2d[i, 1]), \n",
    "                    xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)')\n",
    "    plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_embeddings(embeddings, documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164bbf06",
   "metadata": {},
   "source": [
    "## Similarity Metrics\n",
    "\n",
    "Different metrics to measure similarity between vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9a6b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarities(embedding1, embedding2):\n",
    "    \"\"\"Calculate different similarity metrics between two embeddings\"\"\"\n",
    "    \n",
    "    # Cosine similarity\n",
    "    cosine_sim = cosine_similarity([embedding1], [embedding2])[0][0]\n",
    "    \n",
    "    # Dot product\n",
    "    dot_product = np.dot(embedding1, embedding2)\n",
    "    \n",
    "    # Euclidean distance (converted to similarity)\n",
    "    euclidean_dist = np.linalg.norm(embedding1 - embedding2)\n",
    "    euclidean_sim = 1 / (1 + euclidean_dist)\n",
    "    \n",
    "    # Manhattan distance (converted to similarity)\n",
    "    manhattan_dist = np.sum(np.abs(embedding1 - embedding2))\n",
    "    manhattan_sim = 1 / (1 + manhattan_dist)\n",
    "    \n",
    "    return {\n",
    "        'cosine_similarity': cosine_sim,\n",
    "        'dot_product': dot_product,\n",
    "        'euclidean_similarity': euclidean_sim,\n",
    "        'manhattan_similarity': manhattan_sim\n",
    "    }\n",
    "\n",
    "# Example: Compare similarities between different document pairs\n",
    "pairs_to_compare = [\n",
    "    (0, 1),  # ML and DL (should be similar)\n",
    "    (0, 6),  # ML and Python (somewhat related)\n",
    "    (0, 3),  # ML and Computer Vision (related but different)\n",
    "]\n",
    "\n",
    "print(\"Similarity Comparisons:\\n\")\n",
    "for idx1, idx2 in pairs_to_compare:\n",
    "    doc1 = documents[idx1][:50] + \"...\" if len(documents[idx1]) > 50 else documents[idx1]\n",
    "    doc2 = documents[idx2][:50] + \"...\" if len(documents[idx2]) > 50 else documents[idx2]\n",
    "    \n",
    "    similarities = calculate_similarities(embeddings[idx1], embeddings[idx2])\n",
    "    \n",
    "    print(f\"Document 1: {doc1}\")\n",
    "    print(f\"Document 2: {doc2}\")\n",
    "    print(f\"Similarities:\")\n",
    "    for metric, value in similarities.items():\n",
    "        print(f\"  {metric}: {value:.4f}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581293e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a similarity heatmap\n",
    "def create_similarity_heatmap(embeddings, documents):\n",
    "    # Calculate cosine similarity matrix\n",
    "    similarity_matrix = cosine_similarity(embeddings)\n",
    "    \n",
    "    # Create short labels for documents\n",
    "    labels = [doc[:20] + \"...\" if len(doc) > 20 else doc for doc in documents]\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(similarity_matrix, \n",
    "                xticklabels=labels, \n",
    "                yticklabels=labels,\n",
    "                annot=True, \n",
    "                fmt='.2f', \n",
    "                cmap='YlOrRd',\n",
    "                square=True)\n",
    "    plt.title('Document Similarity Matrix (Cosine Similarity)')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "create_similarity_heatmap(embeddings, documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfd56b5",
   "metadata": {},
   "source": [
    "## Vector Databases\n",
    "\n",
    "Vector databases are specialized databases optimized for storing and querying high-dimensional vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e2ce78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using FAISS for vector similarity search\n",
    "class FAISSVectorDB:\n",
    "    def __init__(self, dimension):\n",
    "        self.dimension = dimension\n",
    "        self.index = faiss.IndexFlatIP(dimension)  # Inner product (cosine similarity)\n",
    "        self.documents = []\n",
    "        \n",
    "    def add_documents(self, embeddings, documents):\n",
    "        \"\"\"Add documents and their embeddings to the index\"\"\"\n",
    "        # Normalize embeddings for cosine similarity\n",
    "        faiss.normalize_L2(embeddings)\n",
    "        self.index.add(embeddings.astype('float32'))\n",
    "        self.documents.extend(documents)\n",
    "        \n",
    "    def search(self, query_embedding, k=5):\n",
    "        \"\"\"Search for k most similar documents\"\"\"\n",
    "        # Normalize query embedding\n",
    "        query_embedding = query_embedding.reshape(1, -1).astype('float32')\n",
    "        faiss.normalize_L2(query_embedding)\n",
    "        \n",
    "        scores, indices = self.index.search(query_embedding, k)\n",
    "        \n",
    "        results = []\n",
    "        for i, (score, idx) in enumerate(zip(scores[0], indices[0])):\n",
    "            if idx < len(self.documents):\n",
    "                results.append({\n",
    "                    'rank': i + 1,\n",
    "                    'document': self.documents[idx],\n",
    "                    'score': float(score),\n",
    "                    'index': int(idx)\n",
    "                })\n",
    "        return results\n",
    "\n",
    "# Create FAISS vector database\n",
    "vector_db = FAISSVectorDB(embeddings.shape[1])\n",
    "vector_db.add_documents(embeddings.copy(), documents)\n",
    "\n",
    "print(f\"Vector database created with {len(documents)} documents\")\n",
    "print(f\"Index size: {vector_db.index.ntotal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7300c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using ChromaDB as an alternative\n",
    "def setup_chromadb():\n",
    "    # Initialize ChromaDB client\n",
    "    client = chromadb.Client()\n",
    "    \n",
    "    # Create a collection\n",
    "    collection = client.create_collection(\n",
    "        name=\"documents\",\n",
    "        metadata={\"hnsw:space\": \"cosine\"}  # Use cosine distance\n",
    "    )\n",
    "    \n",
    "    # Add documents to the collection\n",
    "    collection.add(\n",
    "        embeddings=embeddings.tolist(),\n",
    "        documents=documents,\n",
    "        ids=[f\"doc_{i}\" for i in range(len(documents))]\n",
    "    )\n",
    "    \n",
    "    return collection\n",
    "\n",
    "# Set up ChromaDB\n",
    "try:\n",
    "    chroma_collection = setup_chromadb()\n",
    "    print(\"ChromaDB collection created successfully\")\n",
    "    print(f\"Collection count: {chroma_collection.count()}\")\n",
    "except Exception as e:\n",
    "    print(f\"ChromaDB setup failed: {e}\")\n",
    "    chroma_collection = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8d3038",
   "metadata": {},
   "source": [
    "## Implementing Vector Search\n",
    "\n",
    "Let's implement a complete semantic search system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89478853",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticSearchEngine:\n",
    "    def __init__(self, model_name='all-MiniLM-L6-v2'):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.vector_db = None\n",
    "        self.documents = []\n",
    "        \n",
    "    def index_documents(self, documents):\n",
    "        \"\"\"Index a collection of documents\"\"\"\n",
    "        print(f\"Indexing {len(documents)} documents...\")\n",
    "        \n",
    "        # Generate embeddings\n",
    "        embeddings = self.model.encode(documents, show_progress_bar=True)\n",
    "        \n",
    "        # Create vector database\n",
    "        self.vector_db = FAISSVectorDB(embeddings.shape[1])\n",
    "        self.vector_db.add_documents(embeddings, documents)\n",
    "        self.documents = documents\n",
    "        \n",
    "        print(f\"Indexing complete. {len(documents)} documents indexed.\")\n",
    "        \n",
    "    def search(self, query, k=5):\n",
    "        \"\"\"Search for documents similar to the query\"\"\"\n",
    "        if self.vector_db is None:\n",
    "            raise ValueError(\"No documents indexed. Call index_documents() first.\")\n",
    "            \n",
    "        # Encode query\n",
    "        query_embedding = self.model.encode([query])[0]\n",
    "        \n",
    "        # Search\n",
    "        results = self.vector_db.search(query_embedding, k)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def explain_search(self, query, k=3):\n",
    "        \"\"\"Search and explain the results\"\"\"\n",
    "        results = self.search(query, k)\n",
    "        \n",
    "        print(f\"Query: '{query}'\\n\")\n",
    "        print(f\"Top {len(results)} most similar documents:\\n\")\n",
    "        \n",
    "        for result in results:\n",
    "            print(f\"Rank {result['rank']}: (Score: {result['score']:.4f})\")\n",
    "            print(f\"Document: {result['document']}\")\n",
    "            print(\"-\" * 60)\n",
    "\n",
    "# Create search engine and index documents\n",
    "search_engine = SemanticSearchEngine()\n",
    "search_engine.index_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0137a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the search engine with different queries\n",
    "test_queries = [\n",
    "    \"artificial intelligence algorithms\",\n",
    "    \"neural network architectures\",\n",
    "    \"programming languages for AI\",\n",
    "    \"understanding human language\",\n",
    "    \"large language models\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(\"=\" * 80)\n",
    "    search_engine.explain_search(query, k=3)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f334f1fc",
   "metadata": {},
   "source": [
    "## RAG Architecture\n",
    "\n",
    "Retrieval-Augmented Generation (RAG) combines retrieval and generation for better responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3252b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRAGSystem:\n",
    "    def __init__(self, search_engine):\n",
    "        self.search_engine = search_engine\n",
    "        \n",
    "    def retrieve_and_generate(self, query, k=3):\n",
    "        \"\"\"Retrieve relevant documents and generate response\"\"\"\n",
    "        # Retrieve relevant documents\n",
    "        retrieved_docs = self.search_engine.search(query, k)\n",
    "        \n",
    "        # Extract document contents\n",
    "        context_docs = [doc['document'] for doc in retrieved_docs]\n",
    "        \n",
    "        # Create context\n",
    "        context = \"\\n\".join([f\"Document {i+1}: {doc}\" for i, doc in enumerate(context_docs)])\n",
    "        \n",
    "        # Simple prompt template (in practice, you'd use a real LLM)\n",
    "        prompt = f\"\"\"\n",
    "Based on the following context documents, answer the question:\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer: [This would be generated by an LLM like GPT-3/4, Claude, etc.]\n",
    "\"\"\"\n",
    "        \n",
    "        return {\n",
    "            'query': query,\n",
    "            'retrieved_documents': retrieved_docs,\n",
    "            'context': context,\n",
    "            'prompt': prompt\n",
    "        }\n",
    "    \n",
    "    def demonstrate_rag(self, query):\n",
    "        \"\"\"Demonstrate the RAG process\"\"\"\n",
    "        result = self.retrieve_and_generate(query)\n",
    "        \n",
    "        print(f\"Query: {result['query']}\\n\")\n",
    "        print(\"=== RETRIEVAL PHASE ===\")\n",
    "        print(\"Retrieved Documents:\")\n",
    "        for doc in result['retrieved_documents']:\n",
    "            print(f\"  {doc['rank']}. (Score: {doc['score']:.3f}) {doc['document']}\")\n",
    "        \n",
    "        print(\"\\n=== GENERATION PHASE ===\")\n",
    "        print(\"Prompt for LLM:\")\n",
    "        print(result['prompt'])\n",
    "\n",
    "# Create RAG system\n",
    "rag_system = SimpleRAGSystem(search_engine)\n",
    "\n",
    "# Demonstrate RAG\n",
    "rag_system.demonstrate_rag(\"What are the main types of machine learning?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dacbde",
   "metadata": {},
   "source": [
    "## Advanced Retrieval Techniques\n",
    "\n",
    "Exploring more sophisticated retrieval methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efee0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridSearchEngine:\n",
    "    \"\"\"Combines semantic and keyword-based search\"\"\"\n",
    "    \n",
    "    def __init__(self, semantic_engine, alpha=0.7):\n",
    "        self.semantic_engine = semantic_engine\n",
    "        self.alpha = alpha  # Weight for semantic search\n",
    "        self.documents = semantic_engine.documents\n",
    "        \n",
    "    def keyword_search(self, query, documents):\n",
    "        \"\"\"Simple keyword-based search using TF-IDF\"\"\"\n",
    "        from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "        from sklearn.metrics.pairwise import cosine_similarity\n",
    "        \n",
    "        # Create TF-IDF vectors\n",
    "        vectorizer = TfidfVectorizer(stop_words='english', lowercase=True)\n",
    "        doc_vectors = vectorizer.fit_transform(documents)\n",
    "        query_vector = vectorizer.transform([query])\n",
    "        \n",
    "        # Calculate similarities\n",
    "        similarities = cosine_similarity(query_vector, doc_vectors)[0]\n",
    "        \n",
    "        # Get top results\n",
    "        results = []\n",
    "        for i, score in enumerate(similarities):\n",
    "            results.append({\n",
    "                'index': i,\n",
    "                'document': documents[i],\n",
    "                'score': float(score)\n",
    "            })\n",
    "        \n",
    "        # Sort by score\n",
    "        results.sort(key=lambda x: x['score'], reverse=True)\n",
    "        return results\n",
    "    \n",
    "    def hybrid_search(self, query, k=5):\n",
    "        \"\"\"Combine semantic and keyword search\"\"\"\n",
    "        # Get semantic search results\n",
    "        semantic_results = self.semantic_engine.search(query, k=len(self.documents))\n",
    "        \n",
    "        # Get keyword search results\n",
    "        keyword_results = self.keyword_search(query, self.documents)\n",
    "        \n",
    "        # Normalize scores\n",
    "        max_semantic = max([r['score'] for r in semantic_results]) if semantic_results else 1\n",
    "        max_keyword = max([r['score'] for r in keyword_results]) if keyword_results else 1\n",
    "        \n",
    "        # Create combined scores\n",
    "        combined_scores = {}\n",
    "        \n",
    "        # Add semantic scores\n",
    "        for result in semantic_results:\n",
    "            idx = result['index']\n",
    "            norm_score = result['score'] / max_semantic\n",
    "            combined_scores[idx] = self.alpha * norm_score\n",
    "        \n",
    "        # Add keyword scores\n",
    "        for result in keyword_results:\n",
    "            idx = result['index']\n",
    "            norm_score = result['score'] / max_keyword\n",
    "            if idx in combined_scores:\n",
    "                combined_scores[idx] += (1 - self.alpha) * norm_score\n",
    "            else:\n",
    "                combined_scores[idx] = (1 - self.alpha) * norm_score\n",
    "        \n",
    "        # Sort by combined score\n",
    "        sorted_results = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Format results\n",
    "        final_results = []\n",
    "        for rank, (idx, score) in enumerate(sorted_results[:k], 1):\n",
    "            final_results.append({\n",
    "                'rank': rank,\n",
    "                'index': idx,\n",
    "                'document': self.documents[idx],\n",
    "                'combined_score': score,\n",
    "                'semantic_score': next((r['score'] for r in semantic_results if r['index'] == idx), 0),\n",
    "                'keyword_score': next((r['score'] for r in keyword_results if r['index'] == idx), 0)\n",
    "            })\n",
    "        \n",
    "        return final_results\n",
    "\n",
    "# Create hybrid search engine\n",
    "hybrid_engine = HybridSearchEngine(search_engine)\n",
    "\n",
    "# Test hybrid search\n",
    "query = \"machine learning programming\"\n",
    "results = hybrid_engine.hybrid_search(query, k=5)\n",
    "\n",
    "print(f\"Hybrid Search Results for: '{query}'\\n\")\n",
    "for result in results:\n",
    "    print(f\"Rank {result['rank']}: Combined Score: {result['combined_score']:.3f}\")\n",
    "    print(f\"  Semantic: {result['semantic_score']:.3f}, Keyword: {result['keyword_score']:.3f}\")\n",
    "    print(f\"  Document: {result['document']}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bfbc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query expansion technique\n",
    "class QueryExpansion:\n",
    "    def __init__(self, search_engine):\n",
    "        self.search_engine = search_engine\n",
    "        \n",
    "    def expand_query_with_synonyms(self, query):\n",
    "        \"\"\"Expand query with synonyms (simplified version)\"\"\"\n",
    "        # Simple synonym dictionary (in practice, use WordNet or word embeddings)\n",
    "        synonyms = {\n",
    "            'machine learning': ['artificial intelligence', 'AI', 'ML'],\n",
    "            'neural networks': ['deep learning', 'neural nets'],\n",
    "            'programming': ['coding', 'development'],\n",
    "            'language': ['linguistic', 'text'],\n",
    "            'computer': ['machine', 'system']\n",
    "        }\n",
    "        \n",
    "        expanded_terms = [query]\n",
    "        query_lower = query.lower()\n",
    "        \n",
    "        for term, syns in synonyms.items():\n",
    "            if term in query_lower:\n",
    "                expanded_terms.extend(syns)\n",
    "        \n",
    "        return expanded_terms\n",
    "    \n",
    "    def search_with_expansion(self, query, k=5):\n",
    "        \"\"\"Search using query expansion\"\"\"\n",
    "        expanded_queries = self.expand_query_with_synonyms(query)\n",
    "        \n",
    "        print(f\"Original query: {query}\")\n",
    "        print(f\"Expanded queries: {expanded_queries}\")\n",
    "        \n",
    "        all_results = {}\n",
    "        \n",
    "        # Search with each expanded query\n",
    "        for exp_query in expanded_queries:\n",
    "            results = self.search_engine.search(exp_query, k=len(self.search_engine.documents))\n",
    "            \n",
    "            for result in results:\n",
    "                idx = result['index']\n",
    "                if idx in all_results:\n",
    "                    all_results[idx]['score'] = max(all_results[idx]['score'], result['score'])\n",
    "                else:\n",
    "                    all_results[idx] = result\n",
    "        \n",
    "        # Sort and return top k\n",
    "        sorted_results = sorted(all_results.values(), key=lambda x: x['score'], reverse=True)\n",
    "        \n",
    "        return sorted_results[:k]\n",
    "\n",
    "# Test query expansion\n",
    "query_expander = QueryExpansion(search_engine)\n",
    "expanded_results = query_expander.search_with_expansion(\"machine learning\", k=3)\n",
    "\n",
    "print(\"\\nResults with query expansion:\")\n",
    "for i, result in enumerate(expanded_results, 1):\n",
    "    print(f\"{i}. (Score: {result['score']:.3f}) {result['document']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f53706c",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### Exercise 1: Build a Document QA System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26af055f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentQASystem:\n",
    "    def __init__(self):\n",
    "        self.search_engine = SemanticSearchEngine()\n",
    "        self.knowledge_base = []\n",
    "        \n",
    "    def add_knowledge_base(self, documents):\n",
    "        \"\"\"Add documents to the knowledge base\"\"\"\n",
    "        self.knowledge_base = documents\n",
    "        self.search_engine.index_documents(documents)\n",
    "        \n",
    "    def answer_question(self, question, k=3):\n",
    "        \"\"\"Answer a question using the knowledge base\"\"\"\n",
    "        # Retrieve relevant documents\n",
    "        relevant_docs = self.search_engine.search(question, k)\n",
    "        \n",
    "        # Simple answer extraction (in practice, use a more sophisticated method)\n",
    "        context = \" \".join([doc['document'] for doc in relevant_docs])\n",
    "        \n",
    "        # For this example, we'll return the most relevant document\n",
    "        if relevant_docs:\n",
    "            best_match = relevant_docs[0]\n",
    "            return {\n",
    "                'question': question,\n",
    "                'answer': best_match['document'],\n",
    "                'confidence': best_match['score'],\n",
    "                'supporting_docs': relevant_docs\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'question': question,\n",
    "                'answer': \"I don't have enough information to answer this question.\",\n",
    "                'confidence': 0.0,\n",
    "                'supporting_docs': []\n",
    "            }\n",
    "\n",
    "# Create QA system with AI knowledge base\n",
    "ai_knowledge = [\n",
    "    \"Machine learning is a subset of artificial intelligence that enables computers to learn without being explicitly programmed.\",\n",
    "    \"Supervised learning uses labeled data to train models, while unsupervised learning finds patterns in unlabeled data.\",\n",
    "    \"Deep learning is a subset of machine learning that uses neural networks with multiple layers.\",\n",
    "    \"Natural language processing enables computers to understand, interpret, and generate human language.\",\n",
    "    \"Computer vision allows machines to interpret and understand visual information from the world.\",\n",
    "    \"Reinforcement learning involves training agents to make decisions through trial and error.\",\n",
    "    \"Neural networks are inspired by the human brain and consist of interconnected nodes called neurons.\",\n",
    "    \"Transformers are a type of neural network architecture that has revolutionized NLP.\",\n",
    "    \"Large language models like GPT are trained on vast amounts of text data.\",\n",
    "    \"AI ethics is important to ensure responsible development and deployment of AI systems.\"\n",
    "]\n",
    "\n",
    "qa_system = DocumentQASystem()\n",
    "qa_system.add_knowledge_base(ai_knowledge)\n",
    "\n",
    "# Test the QA system\n",
    "questions = [\n",
    "    \"What is machine learning?\",\n",
    "    \"How does deep learning work?\",\n",
    "    \"What are transformers in AI?\",\n",
    "    \"Why is AI ethics important?\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    result = qa_system.answer_question(question)\n",
    "    print(f\"Q: {result['question']}\")\n",
    "    print(f\"A: {result['answer']}\")\n",
    "    print(f\"Confidence: {result['confidence']:.3f}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172f7691",
   "metadata": {},
   "source": [
    "### Exercise 2: Evaluate Search Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2285a61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_search_quality(search_engine, test_cases):\n",
    "    \"\"\"Evaluate search quality using test cases\"\"\"\n",
    "    \n",
    "    total_precision = 0\n",
    "    total_recall = 0\n",
    "    total_mrr = 0  # Mean Reciprocal Rank\n",
    "    \n",
    "    for case in test_cases:\n",
    "        query = case['query']\n",
    "        relevant_docs = set(case['relevant_doc_indices'])\n",
    "        \n",
    "        # Get search results\n",
    "        results = search_engine.search(query, k=5)\n",
    "        retrieved_indices = set([r['index'] for r in results])\n",
    "        \n",
    "        # Calculate precision and recall\n",
    "        if retrieved_indices:\n",
    "            precision = len(relevant_docs & retrieved_indices) / len(retrieved_indices)\n",
    "            recall = len(relevant_docs & retrieved_indices) / len(relevant_docs) if relevant_docs else 0\n",
    "        else:\n",
    "            precision = recall = 0\n",
    "        \n",
    "        # Calculate MRR\n",
    "        mrr = 0\n",
    "        for rank, result in enumerate(results, 1):\n",
    "            if result['index'] in relevant_docs:\n",
    "                mrr = 1 / rank\n",
    "                break\n",
    "        \n",
    "        total_precision += precision\n",
    "        total_recall += recall\n",
    "        total_mrr += mrr\n",
    "        \n",
    "        print(f\"Query: {query}\")\n",
    "        print(f\"  Precision: {precision:.3f}, Recall: {recall:.3f}, MRR: {mrr:.3f}\")\n",
    "        print(f\"  Retrieved: {list(retrieved_indices)}, Relevant: {list(relevant_docs)}\")\n",
    "    \n",
    "    # Calculate averages\n",
    "    n_cases = len(test_cases)\n",
    "    avg_precision = total_precision / n_cases\n",
    "    avg_recall = total_recall / n_cases\n",
    "    avg_mrr = total_mrr / n_cases\n",
    "    f1_score = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall) if (avg_precision + avg_recall) > 0 else 0\n",
    "    \n",
    "    print(\"\\n=== OVERALL PERFORMANCE ===\")\n",
    "    print(f\"Average Precision: {avg_precision:.3f}\")\n",
    "    print(f\"Average Recall: {avg_recall:.3f}\")\n",
    "    print(f\"F1 Score: {f1_score:.3f}\")\n",
    "    print(f\"Mean Reciprocal Rank: {avg_mrr:.3f}\")\n",
    "\n",
    "# Create test cases\n",
    "test_cases = [\n",
    "    {\n",
    "        'query': 'neural networks and deep learning',\n",
    "        'relevant_doc_indices': [1, 7]  # Deep learning and Transformers\n",
    "    },\n",
    "    {\n",
    "        'query': 'natural language understanding',\n",
    "        'relevant_doc_indices': [2, 7, 9]  # NLP, Transformers, BERT\n",
    "    },\n",
    "    {\n",
    "        'query': 'programming for AI',\n",
    "        'relevant_doc_indices': [6]  # Python programming\n",
    "    }\n",
    "]\n",
    "\n",
    "# Evaluate search engine\n",
    "evaluate_search_quality(search_engine, test_cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efdbf35",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this module, we covered:\n",
    "- Semantic search concepts and applications\n",
    "- Vector embeddings and similarity metrics\n",
    "- Vector databases (FAISS, ChromaDB)\n",
    "- Implementation of semantic search systems\n",
    "- RAG (Retrieval-Augmented Generation) architecture\n",
    "- Advanced retrieval techniques (hybrid search, query expansion)\n",
    "- Search quality evaluation metrics\n",
    "\n",
    "## Next Steps\n",
    "In the next module, we'll build a complete search engine from scratch, implementing more sophisticated indexing and ranking algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f0c605",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "- [Sentence Transformers Documentation](https://www.sbert.net/)\n",
    "- [FAISS Documentation](https://faiss.ai/)\n",
    "- [ChromaDB Documentation](https://docs.trychroma.com/)\n",
    "- [Pinecone Vector Database](https://www.pinecone.io/)\n",
    "- [RAG Paper: Retrieval-Augmented Generation](https://arxiv.org/abs/2005.11401)\n",
    "- [Dense Passage Retrieval](https://arxiv.org/abs/2004.04906)\n",
    "- [ColBERT: Efficient and Effective Passage Search](https://arxiv.org/abs/2004.12832)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
